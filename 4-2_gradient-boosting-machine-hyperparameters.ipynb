{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prerequisites"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_state = 42\n",
    "random_state"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Otto Group Product Classification Challenge\n",
    "\n",
    "이번 과제는 세계 최대의 전자상거래 회사 중 하나인 [Otto Group](https://www.ottogroup.com/)에서 주최하는 [Otto Group Product Classification Challenge](https://www.kaggle.com/c/otto-group-product-classification-challenge/) 경진대회에 참석해보겠습니다.\n",
    "\n",
    "Otto Group은 익명화(anonymization)된 상품 정보에 대한 데이터를 제공하는데, 경진대회 참석자는 이 데이터를 활용하여 주어진 상품 카테고리(target)를 예측해야 합니다. 상품 카테고리는 Class_1부터 Class_9까지 총 9개가 있습니다. 주어진 데이터를 Decision Tree, Random Forest, 그리고 Gradient Boosting Machine를 활용하여 예측해보도록 하겠습니다.\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61878, 94)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_2</th>\n",
       "      <th>feat_3</th>\n",
       "      <th>feat_4</th>\n",
       "      <th>feat_5</th>\n",
       "      <th>feat_6</th>\n",
       "      <th>feat_7</th>\n",
       "      <th>feat_8</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>feat_10</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>Class_1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 94 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    feat_1  feat_2  feat_3  feat_4  feat_5  feat_6  feat_7  feat_8  feat_9  \\\n",
       "id                                                                           \n",
       "1        1       0       0       0       0       0       0       0       0   \n",
       "2        0       0       0       0       0       0       0       1       0   \n",
       "3        0       0       0       0       0       0       0       1       0   \n",
       "4        1       0       0       1       6       1       5       0       0   \n",
       "5        0       0       0       0       0       0       0       0       0   \n",
       "\n",
       "    feat_10   ...     feat_85  feat_86  feat_87  feat_88  feat_89  feat_90  \\\n",
       "id            ...                                                            \n",
       "1         0   ...           1        0        0        0        0        0   \n",
       "2         0   ...           0        0        0        0        0        0   \n",
       "3         0   ...           0        0        0        0        0        0   \n",
       "4         1   ...           0        1        2        0        0        0   \n",
       "5         0   ...           1        0        0        0        0        1   \n",
       "\n",
       "    feat_91  feat_92  feat_93   target  \n",
       "id                                      \n",
       "1         0        0        0  Class_1  \n",
       "2         0        0        0  Class_1  \n",
       "3         0        0        0  Class_1  \n",
       "4         0        0        0  Class_1  \n",
       "5         0        0        0  Class_1  \n",
       "\n",
       "[5 rows x 94 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "data = pd.read_csv(\"data/train.csv\", index_col=\"id\")\n",
    "\n",
    "print(data.shape)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'target'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "label_name = \"target\"\n",
    "label_name"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Index(['feat_1', 'feat_10', 'feat_11', 'feat_12', 'feat_13', 'feat_14',\n",
       "       'feat_15', 'feat_16', 'feat_17', 'feat_18', 'feat_19', 'feat_2',\n",
       "       'feat_20', 'feat_21', 'feat_22', 'feat_23', 'feat_24', 'feat_25',\n",
       "       'feat_26', 'feat_27', 'feat_28', 'feat_29', 'feat_3', 'feat_30',\n",
       "       'feat_31', 'feat_32', 'feat_33', 'feat_34', 'feat_35', 'feat_36',\n",
       "       'feat_37', 'feat_38', 'feat_39', 'feat_4', 'feat_40', 'feat_41',\n",
       "       'feat_42', 'feat_43', 'feat_44', 'feat_45', 'feat_46', 'feat_47',\n",
       "       'feat_48', 'feat_49', 'feat_5', 'feat_50', 'feat_51', 'feat_52',\n",
       "       'feat_53', 'feat_54', 'feat_55', 'feat_56', 'feat_57', 'feat_58',\n",
       "       'feat_59', 'feat_6', 'feat_60', 'feat_61', 'feat_62', 'feat_63',\n",
       "       'feat_64', 'feat_65', 'feat_66', 'feat_67', 'feat_68', 'feat_69',\n",
       "       'feat_7', 'feat_70', 'feat_71', 'feat_72', 'feat_73', 'feat_74',\n",
       "       'feat_75', 'feat_76', 'feat_77', 'feat_78', 'feat_79', 'feat_8',\n",
       "       'feat_80', 'feat_81', 'feat_82', 'feat_83', 'feat_84', 'feat_85',\n",
       "       'feat_86', 'feat_87', 'feat_88', 'feat_89', 'feat_9', 'feat_90',\n",
       "       'feat_91', 'feat_92', 'feat_93'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_names = data.columns.difference([label_name])\n",
    "\n",
    "print(len(feature_names))\n",
    "feature_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(61878, 93)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feat_1</th>\n",
       "      <th>feat_10</th>\n",
       "      <th>feat_11</th>\n",
       "      <th>feat_12</th>\n",
       "      <th>feat_13</th>\n",
       "      <th>feat_14</th>\n",
       "      <th>feat_15</th>\n",
       "      <th>feat_16</th>\n",
       "      <th>feat_17</th>\n",
       "      <th>feat_18</th>\n",
       "      <th>...</th>\n",
       "      <th>feat_85</th>\n",
       "      <th>feat_86</th>\n",
       "      <th>feat_87</th>\n",
       "      <th>feat_88</th>\n",
       "      <th>feat_89</th>\n",
       "      <th>feat_9</th>\n",
       "      <th>feat_90</th>\n",
       "      <th>feat_91</th>\n",
       "      <th>feat_92</th>\n",
       "      <th>feat_93</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 93 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    feat_1  feat_10  feat_11  feat_12  feat_13  feat_14  feat_15  feat_16  \\\n",
       "id                                                                          \n",
       "1        1        0        1        0        0        0        0        0   \n",
       "2        0        0        0        0        0        0        0        0   \n",
       "3        0        0        0        0        0        0        0        0   \n",
       "4        1        1        1        0        1        0        0        1   \n",
       "5        0        0        0        0        0        0        0        0   \n",
       "\n",
       "    feat_17  feat_18   ...     feat_85  feat_86  feat_87  feat_88  feat_89  \\\n",
       "id                     ...                                                   \n",
       "1         2        0   ...           1        0        0        0        0   \n",
       "2         0        2   ...           0        0        0        0        0   \n",
       "3         1        0   ...           0        0        0        0        0   \n",
       "4         1        0   ...           0        1        2        0        0   \n",
       "5         4        0   ...           1        0        0        0        0   \n",
       "\n",
       "    feat_9  feat_90  feat_91  feat_92  feat_93  \n",
       "id                                              \n",
       "1        0        0        0        0        0  \n",
       "2        0        0        0        0        0  \n",
       "3        0        0        0        0        0  \n",
       "4        0        0        0        0        0  \n",
       "5        0        1        0        0        0  \n",
       "\n",
       "[5 rows x 93 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = data[feature_names]\n",
    "\n",
    "print(X.shape)\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Class_1' 'Class_2' 'Class_3' 'Class_4' 'Class_5' 'Class_6' 'Class_7'\n",
      " 'Class_8' 'Class_9']\n",
      "(61878,)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id\n",
       "1    Class_1\n",
       "2    Class_1\n",
       "3    Class_1\n",
       "4    Class_1\n",
       "5    Class_1\n",
       "Name: target, dtype: object"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = data[label_name]\n",
    "\n",
    "print(y.unique())\n",
    "\n",
    "print(y.shape)\n",
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hold-Out Validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(43314, 93) (43314,)\n",
      "(18564, 93) (18564,)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy(train) = 0.802281\n",
      "Accuracy(test) = 0.787330\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "model = GradientBoostingClassifier(random_state=42)\n",
    "\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "y_train_predict = model.predict(X_train)\n",
    "y_test_predict = model.predict(X_test)\n",
    "\n",
    "train_score = (y_train_predict == y_train).mean()\n",
    "test_score = (y_test_predict == y_test).mean()\n",
    "\n",
    "print(f\"Accuracy(train) = {train_score:.6f}\")\n",
    "print(f\"Accuracy(test) = {test_score:.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Hyperparameter"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** n_estimators **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 30.3 s, sys: 735 ms, total: 31.1 s\n",
      "Wall time: 34.5 s\n",
      "n_estimators = 10, train = 0.720091, test = 0.721342\n",
      "CPU times: user 1min 31s, sys: 1.8 s, total: 1min 33s\n",
      "Wall time: 1min 43s\n",
      "n_estimators = 30, train = 0.758808, test = 0.757003\n",
      "CPU times: user 2min 47s, sys: 3.55 s, total: 2min 51s\n",
      "Wall time: 3min 41s\n",
      "n_estimators = 50, train = 0.777785, test = 0.772517\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, monitor)\u001b[0m\n\u001b[1;32m   1032\u001b[0m         \u001b[0;31m# fit the boosting stages\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1033\u001b[0m         n_stages = self._fit_stages(X, y, y_pred, sample_weight, random_state,\n\u001b[0;32m-> 1034\u001b[0;31m                                     begin_at_stage, monitor, X_idx_sorted)\n\u001b[0m\u001b[1;32m   1035\u001b[0m         \u001b[0;31m# change shape of arrays after fit (early-stopping or additional ests)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1036\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mn_stages\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stages\u001b[0;34m(self, X, y, y_pred, sample_weight, random_state, begin_at_stage, monitor, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1087\u001b[0m             y_pred = self._fit_stage(i, X, y, y_pred, sample_weight,\n\u001b[1;32m   1088\u001b[0m                                      \u001b[0msample_mask\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrandom_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1089\u001b[0;31m                                      X_csc, X_csr)\n\u001b[0m\u001b[1;32m   1090\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1091\u001b[0m             \u001b[0;31m# track deviance (= loss)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_fit_stage\u001b[0;34m(self, i, X, y, y_pred, sample_weight, sample_mask, random_state, X_idx_sorted, X_csc, X_csr)\u001b[0m\n\u001b[1;32m    786\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    787\u001b[0m                 tree.fit(X, residual, sample_weight=sample_weight,\n\u001b[0;32m--> 788\u001b[0;31m                          check_input=False, X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m    789\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    790\u001b[0m             \u001b[0;31m# update tree leaves\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m   1122\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1123\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1124\u001b[0;31m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[1;32m   1125\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1126\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/tree/tree.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[1;32m    360\u001b[0m                                            min_impurity_split)\n\u001b[1;32m    361\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 362\u001b[0;31m         \u001b[0mbuilder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    363\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    364\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'tree_'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m----------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-9-aba0d594330a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m     \u001b[0mget_ipython\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmagic\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'time model.fit(X_train, y_train)'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m     \u001b[0my_train_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m     \u001b[0my_test_predict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1530\u001b[0m             \u001b[0mThe\u001b[0m \u001b[0mpredicted\u001b[0m \u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1531\u001b[0m         \"\"\"\n\u001b[0;32m-> 1532\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1533\u001b[0m         \u001b[0mdecisions\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_score_to_decision\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1534\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclasses_\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtake\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdecisions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36mdecision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1485\u001b[0m         \"\"\"\n\u001b[1;32m   1486\u001b[0m         \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mDTYPE\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"C\"\u001b[0m\u001b[0;34m,\u001b[0m  \u001b[0maccept_sparse\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'csr'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1487\u001b[0;31m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1488\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1489\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mravel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/gradient_boosting.py\u001b[0m in \u001b[0;36m_decision_function\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m   1129\u001b[0m         \u001b[0;31m# not doing input validation.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1130\u001b[0m         \u001b[0mscore\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_init_decision_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1131\u001b[0;31m         \u001b[0mpredict_stages\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mestimators_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1132\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mscore\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1133\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32msklearn/ensemble/_gradient_boosting.pyx\u001b[0m in \u001b[0;36msklearn.ensemble._gradient_boosting.predict_stages\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'tree_'"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "n_estimators_list = [10, 30, 50, 100, 300]\n",
    "\n",
    "history = []\n",
    "\n",
    "for n_estimators in n_estimators_list:\n",
    "    model = GradientBoostingClassifier(n_estimators = n_estimators,\n",
    "                                       random_state=42)\n",
    "    \n",
    "    %time model.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_predict = model.predict(X_train)\n",
    "    y_test_predict = model.predict(X_test)\n",
    "    \n",
    "    train_score = (y_train_predict == y_train).mean()\n",
    "    test_score = (y_test_predict == y_test).mean()\n",
    "    \n",
    "    print(f\"n_estimators = {n_estimators}, train = {train_score:.6f}, test = {test_score:.6f}\")\n",
    "    \n",
    "    history.append({\n",
    "        'n_estimators': n_estimators,\n",
    "        'accuracy(train)': train_score,\n",
    "        'accuracy(test)': test_score,\n",
    "    })\n",
    "    \n",
    "history = pd.DataFrame(history)\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history['n_estimators'], history[\"accuracy(train)\"], label='acuracy(train)')\n",
    "plt.plot(history['n_estimators'], history[\"accuracy(test)\"], label='acuracy(test)')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** learning_rate **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 13s, sys: 1.47 s, total: 1min 15s\n",
      "Wall time: 1min 19s\n",
      "learning_rate = 1.0, train = 0.694187, test = 0.678248\n",
      "CPU times: user 1min 38s, sys: 2.48 s, total: 1min 41s\n",
      "Wall time: 2min 27s\n",
      "learning_rate = 0.1, train = 0.758808, test = 0.757003\n",
      "CPU times: user 1min 34s, sys: 2.41 s, total: 1min 36s\n",
      "Wall time: 2min 22s\n",
      "learning_rate = 0.01, train = 0.674886, test = 0.674477\n",
      "CPU times: user 1min 24s, sys: 1.57 s, total: 1min 26s\n",
      "Wall time: 1min 31s\n",
      "learning_rate = 0.001, train = 0.580782, test = 0.581017\n",
      "CPU times: user 1min 14s, sys: 1.31 s, total: 1min 15s\n",
      "Wall time: 1min 20s\n",
      "learning_rate = 0.0001, train = 0.261394, test = 0.258565\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy(test)</th>\n",
       "      <th>accuracy(train)</th>\n",
       "      <th>learning_rate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.678248</td>\n",
       "      <td>0.694187</td>\n",
       "      <td>1.0000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.757003</td>\n",
       "      <td>0.758808</td>\n",
       "      <td>0.1000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.674477</td>\n",
       "      <td>0.674886</td>\n",
       "      <td>0.0100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.581017</td>\n",
       "      <td>0.580782</td>\n",
       "      <td>0.0010</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.258565</td>\n",
       "      <td>0.261394</td>\n",
       "      <td>0.0001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy(test)  accuracy(train)  learning_rate\n",
       "0        0.678248         0.694187         1.0000\n",
       "1        0.757003         0.758808         0.1000\n",
       "2        0.674477         0.674886         0.0100\n",
       "3        0.581017         0.580782         0.0010\n",
       "4        0.258565         0.261394         0.0001"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "learning_rate_list = [1.0, 0.1, 0.01, 0.001, 0.0001]\n",
    "\n",
    "history = []\n",
    "\n",
    "for learning_rate in learning_rate_list:\n",
    "    model = GradientBoostingClassifier(n_estimators = 30,\n",
    "                                       learning_rate = learning_rate,\n",
    "                                       random_state=42)\n",
    "    \n",
    "    %time model.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_predict = model.predict(X_train)\n",
    "    y_test_predict = model.predict(X_test)\n",
    "    \n",
    "    train_score = (y_train_predict == y_train).mean()\n",
    "    test_score = (y_test_predict == y_test).mean()\n",
    "    \n",
    "    print(f\"learning_rate = {learning_rate}, train = {train_score:.6f}, test = {test_score:.6f}\")\n",
    "    \n",
    "    history.append({\n",
    "        'learning_rate': learning_rate,\n",
    "        'accuracy(train)': train_score,\n",
    "        'accuracy(test)': test_score,\n",
    "    })\n",
    "    \n",
    "history = pd.DataFrame(history)\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a177c6ef0>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXcAAAD8CAYAAACMwORRAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nSNXnqb9d2cgAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a16844f28>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.plot(history['learning_rate'], history[\"accuracy(train)\"], label='acuracy(train)')\n",
    "plt.plot(history['learning_rate'], history[\"accuracy(test)\"], label='acuracy(test)')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** subsample **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22.3 s, sys: 302 ms, total: 22.6 s\n",
      "Wall time: 23.1 s\n",
      "subsample = 0.1, train = 0.754213, test = 0.750539\n",
      "CPU times: user 30.5 s, sys: 261 ms, total: 30.8 s\n",
      "Wall time: 30.8 s\n",
      "subsample = 0.3, train = 0.756453, test = 0.755656\n",
      "CPU times: user 39.2 s, sys: 721 ms, total: 40 s\n",
      "Wall time: 40 s\n",
      "subsample = 0.5, train = 0.757907, test = 0.757003\n",
      "CPU times: user 40.6 s, sys: 633 ms, total: 41.2 s\n",
      "Wall time: 41.3 s\n",
      "subsample = 0.7, train = 0.757977, test = 0.757972\n",
      "CPU times: user 38.5 s, sys: 674 ms, total: 39.2 s\n",
      "Wall time: 39.3 s\n",
      "subsample = 0.9, train = 0.757677, test = 0.756949\n",
      "CPU times: user 38.4 s, sys: 548 ms, total: 39 s\n",
      "Wall time: 39.1 s\n",
      "subsample = 1.0, train = 0.758808, test = 0.757003\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>accuracy(test)</th>\n",
       "      <th>accuracy(train)</th>\n",
       "      <th>subsample</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.750539</td>\n",
       "      <td>0.754213</td>\n",
       "      <td>0.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.755656</td>\n",
       "      <td>0.756453</td>\n",
       "      <td>0.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.757003</td>\n",
       "      <td>0.757907</td>\n",
       "      <td>0.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.757972</td>\n",
       "      <td>0.757977</td>\n",
       "      <td>0.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.756949</td>\n",
       "      <td>0.757677</td>\n",
       "      <td>0.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.757003</td>\n",
       "      <td>0.758808</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   accuracy(test)  accuracy(train)  subsample\n",
       "0        0.750539         0.754213        0.1\n",
       "1        0.755656         0.756453        0.3\n",
       "2        0.757003         0.757907        0.5\n",
       "3        0.757972         0.757977        0.7\n",
       "4        0.756949         0.757677        0.9\n",
       "5        0.757003         0.758808        1.0"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsample_list = [0.1, 0.3, 0.5, 0.7, 0.9, 1.0]\n",
    "\n",
    "history = []\n",
    "\n",
    "for subsample in subsample_list:\n",
    "    model = GradientBoostingClassifier(n_estimators = 30,\n",
    "                                       subsample = subsample,\n",
    "                                       random_state = 42)\n",
    "    \n",
    "    %time model.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_predict = model.predict(X_train)\n",
    "    y_test_predict = model.predict(X_test)\n",
    "    \n",
    "    train_score = (y_train_predict == y_train).mean()\n",
    "    test_score = (y_test_predict == y_test).mean()\n",
    "    \n",
    "    print(f\"subsample = {subsample}, train = {train_score:.6f}, test = {test_score:.6f}\")\n",
    "    \n",
    "    history.append({\n",
    "        'subsample': subsample,\n",
    "        'accuracy(train)': train_score,\n",
    "        'accuracy(test)': test_score,\n",
    "    })\n",
    "    \n",
    "history = pd.DataFrame(history)\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x1a15b5af98>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD8CAYAAAB3u9PLAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz\nAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDIuMS4wLCBo\ndHRwOi8vbWF0cGxvdGxpYi5vcmcvpW3flQAAIABJREFUeJzt3Xd8VFX+//HXSU+AhJLQCb2XJBCK\nSFNAsYCKIkXXZV0bKLriz13XhmJZvioWbMC62EBBsUVsdAUETAIYOoSaEHoISUidmfP74w5hAgkZ\nQmbuzOTzfDzyyOTOnbmf3MB9z7n3nnOU1hohhBDCz+wChBBCeAYJBCGEEIAEghBCCDsJBCGEEIAE\nghBCCDsJBCGEEIAEghBCCDsJBCGEEIAEghBCCLsAswu4FJGRkbpFixZmlyGEEF4lOTn5hNY6qqL1\nvCoQWrRoQVJSktllCCGEV1FKHXBmPTllJIQQApBAEEIIYSeBIIQQAvCyawhlKS4uJj09nYKCArNL\nERcREhJC06ZNCQwMNLsUIUQ5vD4Q0tPTqVWrFi1atEApZXY5ogxaa06ePEl6ejotW7Y0uxwhRDm8\n/pRRQUEB9erVkzDwYEop6tWrJ604ITyc1wcCIGHgBeRvJITn84lAEEIIX3Usu4Cp32+j2Gpz+bYk\nEHzct99+y9SpU0seb9u27ZLfIyEhgWnTpl10nePHjzNs2LBK1SiEKFvygVPc+PZq5iceZMfhHJdv\nTwLBw2itsdmq7pPAK6+8wsSJE4GLB4LFYin3PUaMGMETTzxx0e1ERUXRqFEj1qxZU/lihRAlPlt/\nkDGz1xIa5M83E6+ka9MIl29TAqEK3HzzzfTo0YPOnTsze/ZsAH7++We6d+9OTEwMgwcPBuC5557j\ntddeK3ldly5d2L9/P/v376djx45MnDiR7t27k5aWxoQJE4iPj6dz585MmTKl5DWJiYn07duXmJgY\nevXqRU5ODv3792fTpk0l61x55ZWkpKSwa9cugoODiYyM5PfffychIYHHH3+c2NhY9uzZw6BBg3jy\nyScZOHAgb731Ft9//z29e/cmLi6OIUOGcPToUQA++ugjHnroIQDGjx/Pww8/TN++fWnVqhULFy4s\ntR/mzZvnuh0tRDVQaLHy76838+Q3m7midSQJD/ajfcNabtm219926uj577eyLSO7St+zU+Nwpgzv\nfNF15syZQ926dcnPz6dnz57cdNNN3Hvvvfz222+0bNmSzMzMCrezc+dOPvzwQ9577z0AXnrpJerW\nrYvVamXw4MGkpKTQoUMHRo8ezYIFC+jZsyfZ2dmEhoZyzz338NFHH/Hmm2+ya9cuCgsL6datGx9+\n+CHdu3cHoG/fvowYMYIbb7yR2267rWS7WVlZ/PrrrwCcOnWKdevWoZTigw8+4JVXXmH69OkX1Hr4\n8GFWr17Njh07GDFiRMn7xcfH8/TTTzu3Y4UQFziWXcADc5PZcDCLiYNa89g17fH3c98NGT4VCGaZ\nMWMG33zzDQBpaWnMnj2bAQMGlNxzX7du3Qrfo3nz5vTp06fk5y+++ILZs2djsVg4fPgw27ZtQylF\no0aN6NmzJwDh4eEAjBo1ihdeeIFXX32VOXPmMH78eMA4cEdFXXyAw9GjR5c8Tk9PZ/To0Rw+fJii\noqJy+wzcfPPN+Pn50alTp5JWBED9+vXJyMio8HcVQlwo+cApJsxNJrfQwnt3dOf6ro3cXoNPBUJF\nn+RdYeXKlSxdupS1a9cSFhbGoEGDiImJYefOnResGxAQUOr6gON9+TVq1Ch5vG/fPl577TUSExOp\nU6cO48ePp6CgAK11mbdvhoWFMXToUL777ju++OKLkhFhQ0NDOX369EXrd9zupEmTmDx5MiNGjGDl\nypU899xzZb4mODi45LHWutTvExoaetHtCSEu9Nn6g0xJ2ELj2qF8+vfebjtFdD65hnCZTp8+TZ06\ndQgLC2PHjh2sW7eOwsJCfv31V/bt2wdQcsqoRYsWbNiwAYANGzaUPH++7OxsatSoQUREBEePHuWn\nn34CoEOHDmRkZJCYmAhATk5OycXge+65h4cffpiePXuWtEg6duxIampqyfvWqlWLnJzy71Q4ffo0\nTZo0AeDjjz++5H2xa9cuunTpcsmvE6K6MvN6QVkkEC7TsGHDsFgsdOvWjWeeeYY+ffoQFRXF7Nmz\nGTlyJDExMSWnZW699VYyMzOJjY3l/fffp127dmW+Z0xMDHFxcXTu3Jm7776bK6+8EoCgoCAWLFjA\npEmTiImJYejQoSWtjB49ehAeHs7f/va3kvcZMGAAGzduLPkUP2bMGF599VXi4uLYs2fPBdt97rnn\nGDVqFP379ycyMvKS98WKFSu44YYbLvl1QlRHR7MLGDt7HZ//cZCJg1rz4fieRISZO9aXcmzye7r4\n+Hh9/gQ527dvp2PHjiZV5DkyMjIYNGgQO3bswM/vXM4/8sgjDB8+nCFDhri8hgEDBvDdd99Rp06d\nMp+Xv5UQhuQDmTwwdwNnCi28NirG5dcLlFLJWuv4itaTFoIP+OSTT+jduzcvvfRSqTAAePLJJ8nL\ny3N5DcePH2fy5MnlhoEQwmD0L1hHmL1/gRkXj8sjLQThNvK3EtVZocXKcwlb+fyPNAa2i2LGmDi3\nnSJytoXgU3cZCSGEJzqaXcAEE/sXOEsCQQghXMjxeoFZ/QucJYEghBAuMm/9AZ5L2Erj2qHMNbF/\ngbMkEIQQooqZeb3gcshdRj6uKoa/Bti0aRM//vhjyc+LFi0qNeieEMJwNLuAMbPX8fkfaUwc1Jo5\nHtC/wFlOBYJSaphSaqdSKlUpdcE4yEqpN5RSm+xfu5RSWQ7PWR2eS3BYPlgptcG+fLVSqk3V/Ere\nzazhrytyfiDccMMNJCQkuOWWViG8RfKBTG58ezU7j+Tw3h3d+eewDh558bg8FQaCUsofeBe4DugE\njFVKdXJcR2v9qNY6VmsdC7wNfO3wdP7Z57TWIxyWvw/cYX/NZ4DXDpPprcNf79mzh2HDhtGjRw/6\n9+/Pjh07APjyyy/p0qULMTExDBgwgKKiIp599lkWLFhAbGwsCxYsQCnFoEGDWLRokTt2sRAeTWvN\nvPUHPLZ/gbOcuYbQC0jVWu8FUErNB24CyvuoORZw5lyCBsLtjyOAyx8m86cn4Mjmy36bUhp2hesu\nPluYtw5/PXjwYGbOnEnbtm1Zv349EydOZPny5UydOpVffvmFJk2akJWVRVBQEFOnTiUpKYl33nmn\npOb4+HhWrVrF7bffXtm9K4TXK7RYmfLdVuYnpjGofRRvjfaO6wVlcSYQmgBpDj+nA73LWlEp1Rxo\nCSx3WByilEoCLMA0rfW39uX3AD8qpfKBbKAPXsobh7/Ozc3l999/Z9SoUSXLCgsLAaOFMX78eG6/\n/XZGjhxZbs0y3LX7aK2x2jTFVk2RxUaR1Uax1UaRxf7dait5ruRnh/WKLZpC+7Jih9cWWXXJz0H5\nx+mQ9St+gcGcaHYtdepG0TAihIbhITSMCKFWiHce5FzpyGlj/oJNaVk8eFVrJg/1zP4FznImEMr6\n7crr3jwGWKi1tjosi9ZaZyilWgHLlVKbtdZ7gEeB67XW65VSjwOvY4RE6Y0rdR9wH0B0dPTFK63g\nk7wreOvw1zabjdq1a5c61XTWzJkzWb9+PT/88AOxsbFlrnO2fl8Z7to42NooPO+AaXzXZRxkzzv4\nOqxfbNXn3sdhnbPvc+5g7Pg67bDeufcpttiMA7nVhisGFWgQkMt1/kncqNYQzzb87P+1Cw9OZ4mt\nOx9b+/GrLYZiAqgR5E+DswERHnLuscP3yJrBXn1AvBRJ+zOZMM/oX/D+Hd25zgtPEZ3PmUBIB5o5\n/NyU8k/vjAEedFygtc6wf9+rlFoJxCmlsoEYrfV6+2oLgJ/LekOt9WxgNhhDVzhRr1tVNPz12VNG\ndevWpUWLFiXn3C91+OtBgwaVGv66Z8+e5OTkEBoaSkBAAPfccw/Dhw+nf//+pYa/njt3bsn7Og5/\nHR4eTsuWLfnyyy8ZNWoUWmtSUlKIiYlhz5499O7dm969e/P999+TlpZW5tDZ3j7cdeqxHN5YupvF\nW49QbK36f1pB/n4E+iuCAvwI9De+ggL8jOUBqmRZjeAA+2NVep1Srzn3XKC/H4H2ZaXe2/F5+/rB\nDusH+iuC/f0JtOQQlPoT/tu+Ru1dCTYL1GsLXf4FXUZCUS7+G+dz3davuDF/PYVBtUmNuoa1NYew\nwRrJkexC1u/L5Gh2ARZb6f3m76eIqhlMg4gQGtlDokF4CA0jgo3v9mVhQd57x7txveAgz3+/lSa1\nQ5l3T2/aNfDs/gXOcuavkgi0VUq1BA5hHPTHnb+SUqo9UAdY67CsDpCntS5USkUCVwKvAKeACKVU\nO631LmAosP1yfxkzDBs2jJkzZ9KtWzfat29/wfDXNpuN+vXrs2TJEm699VY++eQTYmNj6dmzp1PD\nX7dq1arM4a/z8/MJDQ1l6dKl1KxZs9zhrx977LGSlsWYMWO49957mTFjBgsXLmTevHlMmDCBF198\nkeLiYsaMGUNMTAyPP/44u3fvRmvN4MGDiYmJITo6mmnTphEbG8u///1vRo8ezYoVK/jPf/7jlv1c\nlQ6cPMNbS3fz7aZDhAb6M65XNJE1g+0HzQsPtKUOrP7KfjAuffB1PIgHBfgR4KfKbM2ZpugM7PwJ\ntn4DuxeDtQhqR0PfSdB5pHGtzKHegCY94LqXYc9ygv+cT+edCXQ+9AXUbQXdRkO327HVbsnJM0Uc\nOV3AkWzj66j98dHsAvYcz2VN6glyCi0XlBMeEnAuLByCo1FJgIRQNywIPw9rbfjS9YKyODW4nVLq\neuBNwB+Yo7V+SSk1FUjSWifY13kOCNFaP+Hwur7ALMCGcUfTm1rr/9mfuwWYan/uFHD32QvX5ZHB\n7crn7uGvjx49yrhx41i2bJnTrzH7b3UoK593lu/mi6R0Av0Vf72iBfcPbE3dGkGm1eRSxQWQuhS2\nfAW7fobiPKjVCDrfAl1uhSY9SoXARRVkw/YE+HM+7F8NaGjWG7rdbgRKWPnXyc4UWkqFxdnHh08b\nwXEku4DjOYWc19gg0F9Rv1bpU1KlTlWFh1A/PJiQQP/K76NL4M3XC5wd3E5GO/UBn3zyCU899RSv\nv/56qYvEYBy4169fz4gRI8p5deUkJiYSGBhIbGys068x6291LLuAd1ek8vkfxr0R43pHM3FQa+qH\nh7i9FpezFsPelUYI7PgBCrMhLBI63WSEQPQV4HeZ/VFPp8PmL+HPBXB8O/gFQttrIGY0tBsGAcEV\nv8d5LFYbJ3KLjMA4XcCR0/kcyS40AsMhOPKKrBe8tk5YIA0jQmkYHlyq1dEgwmhxNAwPISI08LJa\nbIn7M5kwdwN5RRamj4rxuusFEgjC47j7b3Uyt5CZv+7hk7UHsNo0o+KbMenqNjSu7RsXwkvYrMan\n9i1fGZ/i809BSAR0HG6EQIsB4O+Cc/ZaG7d5pyyAzQsh94ix3U43Q8wYaNbn8sOn1OY02QWWkpA4\n/xTV2RbHidyiC14bHOB3wSmqhqWucYRQv1Ywgf5+F2xz7vqDPJ+wlaZ1Qpl9V7xXXi+oVsNfl3f3\njfAc7vzgcTqvmNmr9vDhmv0UFFu5Ja4pjwxuS3S9MLfV4HI2G6T/YYTA1m/hzDEIqgntrzdCoPXV\nEODiU2FKQaNuxtfQqUbLJOULIxw2fGxco+h6u3HNIars62WXtjlFRGggEaGBFz0oF1lsHMuxtypO\nF3L4dL69hVHI0dMFbErL4sjWAoospUcEUArq1QimYUQwDcNDaRgRzKkzxfyw+TBXtY/izTFxRIT6\nzvWCsnh9C2Hfvn3UqlWLevXqSSh4KK01J0+eJCcnp6RvhivkFBQzZ/V+Pli9l5wCC8NjGvPI4La0\nqV/TZdt0K60hYyNs/Rq2fAPZ6RAQAu2uNc7jt70Ggjwg9ApzjdNVKQtg7wrQNmgcB93GGGFVs+y+\nMe6ktSYrr7jUdYwj5z0+kl3AmUIL9w9ozaND23nN9YKyVJtTRsXFxaSnp5e6p194npCQEJo2bUpg\nYNV/wsorsvDJ2gPM/HUPWXnFXNu5AY8ObUeHhuEVv9gbHN1mtAS2fAWn9hnn7NsMNg6u7a+DYA8+\nhZFzxKj7z/lwJAWUv1F7t9FGa8YTAuwibDbtcXc6VUa1CQRRfRUUW/ls/UHeW5nKidwiBrWPYvLQ\ndnRrWtvs0i7fiVR7S+ArOL7DOJC2HGCEQMcbIdQL564+tt1oNaR8abRugmpBpxHGnUot+oOfe+4W\nqo4kEITPKrLY+CIpjXeWp3Iku4C+revx2DXt6NG84iFCPFrWQdhiD4EjKYCC5n2NzmIdb/KIUy1V\nwmaDA2sgZT5sSzDuhKrVGLqNMloODTqbXaHPkUAQPsditfH1xkPMWLab9FP59Gheh8eGtqNvm0iz\nS6u87MOw7VsjCNL/MJY1iTdaAp1vhvDG5tbnasX5Roe5lAVGnwmbBRp0NW5h7XIbhHvX7Z2eSgJB\n+AyrTbMoJYM3l+5m34kzdG0SwWPXtGNguyjvvJHgzEnY/p0RAmc7eTXsag+BW6BOC7MrNMeZE8Y+\nSVkAh5JA+UHLgUaroeNwCPaRmwNMIIEgvJ7Wml+2HuH1JbvYdTSXDg1rMXloO4Z2auB9QZCfZdx5\ns+Ur4/ZMbYXIdsan4C4jIbKt2RV6lhOp9usNCyDrAASGQYcbjDuVWg1yTb8KHyaBILyW1poVO48x\nffEutmZk0yqqBo8OaccNXRt51x0fhbnGkBFbvjJOh1iLjE//nUcarYEGnZ0fOqK60hrS1ht3KW39\nBgqyoEZ96Hqb0XJoFCP70AkSCMLraK1Zk3qS1xbvZFNaFtF1w3hkcFtuim1MgL+XTP9dnA+7l9jH\nD/oFLPnGBdMuI42vxt3lAFZZlkJjYL6UBca+tRZBVAfjLqWut0PtZhW/RzUlgSC8yh/7Mpm+eCfr\n92XSOCKESYPbcluPphcMJeCRLEVGB6wtXxunhYpyoEaUMYRDl1uNQeCqcAgHAeRlwrbvjHA4aB9g\nuXk/42J0p5uMITRECQkE4RU2pWUxffFOVu0+QVStYB66qg1jejUjOMDD70m3WuCAffygbQnGqYyQ\n2sZ99V1uNQ5Ocp7bPU7tN/o2pMyHk6ngH2x02IsZA60Hu34IDy8ggSA82taM07yxZBdLtx+jbo0g\nJgxszZ19mhMa5MFBYLMZ57O3fGXcKnrmuNG5qsMNxumgVlfJwcdMWsOhDUarYctCyDsJoXWNgI4Z\nc2nDffsYCQThkXYfzeGNpbv4cfMRwkMCuG9AK8Zf2ZKawR76aVpryNhgnA7a+g1kH4KAUGP8oC63\nQtuhEOhjo6f6Amsx7FluXIze+SNYCqBu65LJfajrujG1PJEEgvAo+06c4a2lu/juzwzCAv35e7+W\n/L1/K88cPVJrOLrVPpLo18YpCb9A4+Df5VZjzH+5J957lDu5z2ij38dFJvfxFRIIwiOkn8rj7WWp\nLNxgn6WsbwvuH+Chs5Sd2H1u6IgTO43xg1oNMkKgww0Q6gNjJFV3ZU3u0+5aIxzaXVupyX28gQSC\nMNWR08YsZfMTD6JQ3NEnmgmDWlO/lofNUpZ7DDbNs48ftBlQ0KKfffygEVDDi4fFEOUrNbnPl5B7\n1LgzqfMtRjhU8eQ+F63DWmzcnlycb0xzWpxvTH9a8jjPOOXV/noIqdwIvhIIwhQncgt5f+UePl13\nAJtNM7pnMx66ug2NIjzsPHvWQVgzAzZ+avxna9rLCIFON8v4OdWNzXpucp/t30PxGWNyn26jjdZh\nSMR5B+vzDt6WMpZdsM55B/jignOP9YXTgpbpwT8gqn2lfkUJBOFWWXlFzPptLx+t2U+hxcrI7sYs\nZc3qeth498d3wuo3YfMXgILYsdD3EYhsY3ZlwhOUNbnPpfALNIbZCAyFwBCHx2HGZEZnHweGnvd1\n9nmH9Uu9PhTCm1b6LrZqNYWmME92QTH/W7WPOav3kVtkYXi3xjwypC2tozzsouuhDbD6ddi+yPjP\n1es+uOIhiGhidmXCkwTXNDq3xYw2JvfZvdgIhQsO2OcdzANDjbvPvLzviXdXL0xzptDCx2v3M+vX\nvZzOL2ZY54Y8OrQd7Rt60OxdWhvj7q+abtyCGBIBAx6H3g9AjXpmVyc8Xa2G0P0us6twKwkEcUkK\niq3MXXeA91fu4eSZIq7uUJ/JQ9vRpYkHDRWgtfHJbtV0oyNZjfow5HmIv7vSF+WEqA4kEIRTCi1W\nvkhM450VqRzNLqRfm0geHdqOHs09aCpHm9XoPLb6DTi6BSKi4frXIO5O6TwmhBMkEMRFFVttfL0h\nnRnLUjmUlU/PFnV4c3QcV7T2oFMulkKj09GaNyFzL0S2h1tmGXeI+HtgxzchPJQEgiiT1aZJ+PMQ\nby3dzf6TecQ0jeA/I7vSv22k50xOU3QGkj+G39+GnAxoFAuj50L7G2R0USEqQQJBlGKzaX62z1KW\neiyXjo3C+eCueAZ3rO85QZB/Cv74L6x7H/IzoUV/uPldY3A5T6lRCC8kgSAAY3KaZduPMX3JLrYf\nzqZN/Zq8O64713Vp6DmzlOUchXXvQuL/oCjXGFOo32SI7m12ZUL4BAmEak5rzardJ5i+ZBd/pmXR\nvF4Yb4yOYURME/w9JQhO7bf3Kp4LtmJjCsp+j0LDLmZXJoRPkUCoxtbtPcnri3fxx/5MmtQO5f9u\n7crI7h40S9mxHcYdQ5u/BOUHsePgykegXmuzKxPCJ0kgVEMbD55i+uJdrE49Qf1awbxwU2du7+lB\ns5QdSoZVr8OORUYv0N4PQN+HILyx2ZUJ4dMkEKoRm03zzopU3li6i7phQTx9Q0fu7NOckEAPCAKt\njbHqV003xpAJiYCB/4Je90uvYiHcRAKhmsguKGbygj9Zuv0ot8Q14cWbu1DDE2Yp0xp2/WwEQXqi\n0at46FTo8TfpVSyEm3nAEUG42u6jOdz/aTIHM/N4bngn/tq3hfm3kFotxrzEq16HY1uN4YZvmA6x\ndxqjPAoh3E4Cwcf9uPkw/+/LPwkLCuCze/vQq6XJ0wVaCuHPz40hqE/tg6gOcMtsYy4C6VUshKkk\nEHyU1aZ59ZedzPx1D3HRtXn/jh40jDDxk3dhLiR/BGvfgZzD0Lg7XPOiMQuU9CoWwiNIIPigzDNF\nPPz5RlannuCO3tE8O7yTeXcQ5WUavYrXv2/0MG45AG5+35ir2OzTVkKIUiQQfMyWQ6e5/9NkjucU\n8sqt3bi9ZzNzCsk5AmvfhaQ5Rq/i9tcbvYqb9TSnHiFEhSQQfMhXyek8+c1m6tYI4ssHriCmWW33\nF3F+r+Iutxq9iht0dn8tQohL4lQgKKWGAW8B/sAHWutp5z3/BnCV/ccwoL7Wurb9OSuw2f7cQa31\nCPtyBbwIjAKswPta6xmX9+tUT0UWGy/9sI2P1x6gT6u6vDOuO5E1g91bxLHt9l7FC8HP/1yv4rqt\n3FuHEKLSKgwEpZQ/8C4wFEgHEpVSCVrrbWfX0Vo/6rD+JCDO4S3ytdaxZbz1eKAZ0EFrbVNK1a/c\nr1C9Hcsp4MF5G0jcf4p7+7fkX8M6EODOoSfSk425incsgsAa0GeCMVdxeCP31SCEqBLOtBB6Aala\n670ASqn5wE3AtnLWHwtMceJ9JwDjtNY2AK31MSdeIxwkHzjFhLnJ5BRYmDE2jhExbhraQWvY95vR\nmWzfrxBSGwY+Ab3vhzCTb2sVQlSaM4HQBEhz+DkdKHO8YaVUc6AlsNxhcYhSKgmwANO01t/al7cG\nRiulbgGOAw9rrXeX8Z73AfcBREdHO1Gu79NaM3f9QaZ+v5XGtUP5+O5edGzkhl69Ntu5XsWHkqBm\nAxj6AsT/DYJruX77QgiXciYQyro3UJez7hhgodba6rAsWmudoZRqBSxXSm3WWu8BgoECrXW8Umok\nMAfof8GGtJ4NzAaIj48vb7vVRkGxlWe+3cKXyelc1T6KN0fHERHm4g5dVgts/dq4RnBsG9RuDje+\nATHjpFexED7EmUBIxzjXf1ZTIKOcdccADzou0Fpn2L/vVUqtxLi+sMf+vl/ZV/sG+NDpqqupQ1n5\nPPBpMpsPnebhq9vwjyHtXDt5TXEB/PkZrHnLuHsoqiOM/K8xH4G/3KAmhK9x5n91ItBWKdUSOIRx\n0B93/kpKqfZAHWCtw7I6QJ7WulApFQlcCbxif/pb4GqMlsFAYNdl/B4+7/fUEzz0+UaKLTb+e1c8\nQzs1cN3GCnMh+UP4/R3IPQJNesC1L0O766RXsRA+rMJA0FpblFIPAb9g3HY6R2u9VSk1FUjSWifY\nVx0LzNdaO57W6QjMUkrZAD+MawhnL0ZPA+YppR4FcoF7quZX8i1aa/67ai/TftpBq6iazPpLD1pH\n1XTNxvIy4Y/ZsH7muV7FI2dBy4HSq1iIakCVPn57tvj4eJ2UlGR2GW6TV2ThnwtTWJRymOu6NOTV\nUTHUdMWQ1dmHjTGGkj6E4jPQ/gboPxmaxlf9toQQbqeUStZaV/gfWk4Ee6j9J85w/6fJ7D6Ww7+G\ndeCBga2qfsjqzH3G9YFN88BmgS632XsVd6ra7QghvIIEggdavuMoj8zfhL+f4uO7e9G/bVTVbuDY\ndmMegi0LwS8A4u6Evg9D3ZZVux0hhFeRQPAgNpvm7eWpvLlsF50ahTPzzh40qxtWtRs5sRtmDTSC\n4IoHoc+D0qtYCAFIIHgMY4rLTSzdfoyRcU14eWRX18x1vGQK+AfBQ3/IpPVCiFIkEDzALvsUl2mZ\neTw/ojN3XdHcNVNc7l8DO3+Aq5+RMBBCXEACwWQ/pBzm8YVumOLSZoPFT0N4E+gz0TXbEEJ4NQkE\nk1isNl5dvJNZv+6le3Rt3r+zBw3CXTgMxNavIWMD3DwTgqr4uoQQwidIIJgg80wRkz7fwJrUk9zR\nO5opwzsTFODCHsCWQlj2PDTsCt1Gu247QgivJoHgZiVTXOa6cYrLP2ZD1kG46zsZekIIUS4JBDda\nmJzOU99spl6NIBY+cAXdmrphisu8TPjtVWgz1JjYXgghyiGB4AZFFhsv/rCNT9Ye4IpW9XhnXBz1\n3DXF5W+vQWEODJ3qnu0JIbyzUYMyAAARy0lEQVSWBIKLHcsuYOK8DSQdOMV9A1rxz2vbu2+Ky8y9\nxumiuDtlOAohRIUkEFwo+UAmE+ZuIKfAwttj4xjurikuz1o2FfwD4aqn3LtdIYRXkkBwAa01c9cd\nYOqibTSuHconf+9Fh4ZumOLSUVoibP3GmOu4VkP3blsI4ZUkEKpYQbGVp7/dwsKzU1yOiSMi1MVT\nXJ5Pa6MTWs0G0HeSe7cthPBaEghVKP1UHhPmbmDzodM8Mrgtjwxu69opLsuz/XtIWwfD34JgF02m\nI4TwORIIVWRN6gke+mwDFqvmg7viGeLKKS4vxlIES6cY8x/H3mlODUIIrySBcJm01sz+bS//9/MO\nWtunuGzlqikunZH8oXF30bgvwV/+vEII58kR4zKcKbTwz69S+CHlMNd3bcgrt7loiktn5WfBymnG\nHMhth5pXhxDCK0kgVNK+E2e4/9MkUo/l8sR1Hbh/gAumuLxUq9+A/FNwzYtgdi1CCK8jgVAJy7Yf\n5R8LNhHgp/jk7t70axtpdknGWEXr3oeYMdCom9nVCCG8kATCJbDZNG8t281by3bTubGLprisrOX2\nVsHVT5tdiRDCS0kgOOl0vjHF5bIdxxjZvQkv3+KiKS4rI2MjpCyAfpMhoqnZ1QghvJQEghN2Hsnh\n/k+TSD+Vz9SbOvOXPi6a4rIytIbFz0BYJPR71OxqhBBeTAKhAotSMvjnwhRqBAfw+X196NnCRVNc\nVtauX2D/Krj+NQhx8/AYQgifIoFQDovVxiu/7GT2b3vp0bwO793R3bVTXFaG1QJLnoV6baDHeLOr\nEUJ4OQmEMjhOcXlnn2ievdHFU1xW1sZP4MROGD3PGNVUCCEugwTCeTann+aBufYpLm/rxu3xbpji\nsjIKc2DFyxDdFzrcYHY1QggfIIHg4MukNJ76dguR7pzisrLWzIAzx2HsAumEJoSoEhIIGFNcvrBo\nG5+uO0Df1vV4e6wbp7isjOwM+P1t6HIrNO1hdjVCCB9R7QPhqH2Ky2QzprisrBUvgbbC4GfNrkQI\n4UOqdSAk7s9k4rwN5Jo1xWVlHNkCG+fBFQ9CnRZmVyOE8CHVMhC01ny67gBTv99G0zqhzP17b9o3\nrGV2Wc5Z8iyERMCA/2d2JUIIH1PtAqGg2MpT32zhqw3pXN2hPm+MjnX/FJeVlboM9iyDa1+G0Dpm\nVyOE8DHVKhDST+XxwNxkthzKNneKy8qwWY3WQZ0W0PMes6sRQvigahMIq3efYNLnxhSX//trPIM7\nmjTFZWX9+Tkc3QK3fQgBHnwHlBDCa/l8IGitmfXbXl75eQdt6tdk1l/iaRlZw+yyLk1RnjG8dZN4\n6HyL2dUIIXyUzweCUoqMrHyu69KIV27rRg0zp7isrLXvQs5hGPWRdEITQriMFx4dL92zN3bC3095\nzpDVlyL3GKx5EzoOh+g+ZlcjhPBhTvXAUkoNU0rtVEqlKqWeKOP5N5RSm+xfu5RSWQ7PWR2eSyjj\ntW8rpXIv79e4uAB/P+8MA4CV/wFLAQx53uxKhBA+rsIWglLKH3gXGAqkA4lKqQSt9baz62itH3VY\nfxIQ5/AW+Vrr2HLeOx7w4AGDTHZ8JyR/bNxVVK+12dUIIXycMy2EXkCq1nqv1roImA/cdJH1xwKf\nV/Sm9qB5FfinM4VWS0umQFANGPgvsysRQlQDzgRCEyDN4ed0+7ILKKWaAy2B5Q6LQ5RSSUqpdUqp\nmx2WPwQkaK0PX2zjSqn77K9POn78uBPl+oh9q2DXT9B/MtSoZ3Y1QohqwJmLymWdfNflrDsGWKi1\ntjosi9ZaZyilWgHLlVKbgXxgFDCooo1rrWcDswHi4+PL265vsdlg8dMQ3hR6P2B2NUKIasKZQEgH\nHGeJaQpklLPuGOBBxwVa6wz7971KqZUY1xfygTZAqv1ib5hSKlVr3eaSqvdVWxbC4U1wy2wIDDW7\nGiFENeHMKaNEoK1SqqVSKgjjoF/W3ULtgTrAWodldZRSwfbHkcCVwDat9Q9a64Za6xZa6xZAnoSB\nXXEBLJsKjWKg6yizqxFCVCMVthC01hal1EPAL4A/MEdrvVUpNRVI0lqfDYexwHytteNpnY7ALKWU\nDSN8pjnenSTKsH4mnE6Dm94FPw+fl0EI4VNU6eO3Z4uPj9dJSUlml+E6Z07CjDhofgWMW2B2NUII\nH6GUStZax1e0nnwE9SS/vQJFOdIJTQhhCgkET3FyDyR+AN3/CvU7mF2NEKIakkDwFEufA/9gGPRv\nsysRQlRTEgie4OA62J4A/f4BtbxsngYhhM+QQDCb1kYntJoN4YoHK15fCCFcpFoMf+3Rtn0L6Ykw\n4h1j3CIhhDCJtBDMZCkyrh3U7wyx48yuRghRzUkLwUyJH8Cp/XDnV+Dnb3Y1QohqTloIZsk/ZfQ7\naHUVtBlidjVCCCGBYJpV0yE/C655wexKhBACkEAwx6kDsH6Wcd2gYVezqxFCCEACwRzLpoLyh6ue\nMrsSIYQoIYHgboeSjfkOrngQIsqceE4IIUwhgeBOWsPiZ6BGlNErWQghPIgEgjvt/BEOrDHGKwqu\nZXY1QghRigSCu1iLYckUiGxnjGgqhBAeRjqmuUvyR3ByN4ydD/6y24UQnkdaCO5QkA0rp0HzftBu\nmNnVCCFEmSQQ3GHNm5B3wuiEppTZ1QghRJkkEFzt9CFY+y50HQVNuptdjRBClEsCwdWWv2jcbnr1\nM2ZXIoQQFyWB4EqHU+DPz6H3/VCnudnVCCHERUkguIrWsOQZCK0N/R8zuxohhKiQBIKrpC6DvSth\n4L+MUBBCCA8ngeAKNqvROqjTEuL/bnY1QgjhFOkh5Qqb5sGxbTDqYwgIMrsaIYRwirQQqlphLix/\nCZr2gk43mV2NEEI4TVoIVW3tO5B7BEZ/Kp3QhBBeRVoIVSnnCKyZYbQMmvUyuxohhLgkEghVacXL\nYC2CwVPMrkQIIS6ZBEJVObYdNn4KPe+Beq3NrkYIIS6ZBEJVWfIsBNWCgf80uxIhhKgUCYSqsHcl\n7F4MAx6DsLpmVyOEEJUigXC5bDZjnuSIaOh1v9nVCCFEpcltp5dr8xdwJAVGfgCBIWZXI4QQlSYt\nhMtRnA/LXoDGcdDlVrOrEUKIyyIthMux7n3IToeRs8BPslUI4d3kKFZZZ07Aqteh/fXQop/Z1Qgh\nxGVzKhCUUsOUUjuVUqlKqSfKeP4NpdQm+9cupVSWw3NWh+cSHJbPs7/nFqXUHKVUYNX8Sm6ychoU\n58GQ582uRAghqkSFp4yUUv7Au8BQIB1IVEolaK23nV1Ha/2ow/qTgDiHt8jXWseW8dbzgDvtjz8D\n7gHev+TfwAwndkPyh9BjPES1M7saIYSoEs60EHoBqVrrvVrrImA+cLFhPMcCn1f0plrrH7Ud8AfQ\n1JmCPcLS5yAgFAb92+xKhBCiyjgTCE2ANIef0+3LLqCUag60BJY7LA5RSiUppdYppW4u4zWBwF+A\nn52u2kwHfocdi6DfI1AzyuxqhBCiyjhzl1FZYzjrctYdAyzUWlsdlkVrrTOUUq2A5UqpzVrrPQ7P\nvwf8prVeVebGlboPuA8gOjraiXJdSGtY/DTUagx9HjS3FiGEqGLOtBDSgWYOPzcFMspZdwznnS7S\nWmfYv+8FVuJwfUEpNQWIAiaXt3Gt9WytdbzWOj4qyuRP5Fu/hkPJcPXTEBRmbi1CCFHFnAmERKCt\nUqqlUioI46CfcP5KSqn2QB1grcOyOkqpYPvjSOBKYJv953uAa4GxWmvb5f4iLmcpNK4dNOgKMWPM\nrkYIIapchaeMtNYWpdRDwC+APzBHa71VKTUVSNJanw2HscB8+0XiszoCs5RSNozwmeZwd9JM4ACw\nVhkzi32ttZ5aJb+VK/zxX8g6CH/5Bvz8za5GCCGqnCp9/PZs8fHxOikpyf0bzsuEGbHQtCfc+ZX7\nty+EEJdBKZWstY6vaD3pqeyMVdOhMAeGem4DRgghLpcEQkUy98H6WRB7BzTobHY1QgjhMhIIFVk2\nFfwD4aqnzK5ECCFcSgLhYtISjVtN+06C8EZmVyOEEC4lgVCes53QatSHvg+bXY0QQricBEJ5diyC\ntHVw1ZMQXNPsaoQQwuUkEMpiLYYlUyCyPcT9xexqhBDCLWTGtLIkfQiZe2DcF+Avu0gIUT1IC+F8\nBadh5X+g5QBoe43Z1QghhNtIIJxv9RuQnwlDXwBV1kCvQgjhmyQQHGWlwdr3oNsYaFzWJG9CCOG7\nJBAcLX/R+H710+bWIYQQJpBAOCtjE6TMhysmQu1mFa8vhBA+RgIBznVCC6sH/R41uxohhDCFBALA\n7sWwfxUMfAJCIsyuRgghTCGBYLXA4megbmuI/5vZ1QghhGmk19XGT+HEThg91xjVVAghqqnq3UIo\nzIEVL0OzPtDhRrOrEUIIU1XvFsLvb8OZYzD2c+mEJoSo9qpvCyH7sBEInW+BphVONSqEED6v+gbC\nipeMUU0HTzG7EiGE8AjVMxCOboWNc6H3/VC3pdnVCCGER6iegbDkWQgJh/6PmV2JEEJ4jOoXCHuW\nQ+pSGPBPCKtrdjVCCOExqlcg2KxGJ7TazaHXvWZXI4QQHqV63Xb653w4ugVumwMBwWZXI4QQHqX6\ntBCK8ozhrZv0gM4jza5GCCE8TvVpIax7F3Iy4Lb/SSc0IYQoQ/VoIeQeg9VvGsNTNO9rdjVCCOGR\nqkcgrJwGlgIY8rzZlQghhMeqHoFQOxr6ToLINmZXIoQQHqt6XEPo9w+zKxBCCI9XPVoIQgghKiSB\nIIQQApBAEEIIYSeBIIQQApBAEEIIYSeBIIQQApBAEEIIYSeBIIQQAgCltTa7BqcppY4DB8yu4zJF\nAifMLsJDyL4oTfZHabI/zrncfdFcax1V0UpeFQi+QCmVpLWON7sOTyD7ojTZH6XJ/jjHXftCThkJ\nIYQAJBCEEELYSSC432yzC/Agsi9Kk/1RmuyPc9yyL+QaghBCCEBaCEIIIewkEFxEKTVMKbVTKZWq\nlHqijOcnK6W2KaVSlFLLlFLNzajTHSraFw7r3aaU0kopn76zxJn9oZS63f7vY6tS6jN31+hOTvxf\niVZKrVBKbbT/f7nejDrdQSk1Ryl1TCm1pZznlVJqhn1fpSiluldpAVpr+ariL8Af2AO0AoKAP4FO\n561zFRBmfzwBWGB23WbtC/t6tYDfgHVAvNl1m/xvoy2wEahj/7m+2XWbvD9mAxPsjzsB+82u24X7\nYwDQHdhSzvPXAz8BCugDrK/K7UsLwTV6Aala671a6yJgPnCT4wpa6xVa6zz7j+uApm6u0V0q3Bd2\nLwCvAAXuLM4EzuyPe4F3tdanALTWx9xcozs5sz80EG5/HAFkuLE+t9Ja/wZkXmSVm4BPtGEdUFsp\n1aiqti+B4BpNgDSHn9Pty8rzd4zU90UV7gulVBzQTGu9yJ2FmcSZfxvtgHZKqTVKqXVKqWFuq879\nnNkfzwF3KqXSgR+BSe4pzSNd6rHlklSPOZXdT5WxrMzbuZRSdwLxwECXVmSei+4LpZQf8AYw3l0F\nmcyZfxsBGKeNBmG0HFcppbporbNcXJsZnNkfY4GPtNbTlVJXAJ/a94fN9eV5HKePLZUhLQTXSAea\nOfzclDKauUqpIcBTwAitdaGbanO3ivZFLaALsFIptR/jvGiCD19YdubfRjrwnda6WGu9D9iJERC+\nyJn98XfgCwCt9VogBGNsn+rIqWNLZUkguEYi0FYp1VIpFQSMARIcV7CfJpmFEQa+fI74ovtCa31a\nax2ptW6htW6BcT1lhNY6yZxyXa7CfxvAtxg3HaCUisQ4hbTXrVW6jzP74yAwGEAp1REjEI67tUrP\nkQDcZb/bqA9wWmt9uKreXE4ZuYDW2qKUegj4BeMuijla661KqalAktY6AXgVqAl8qZQCOKi1HmFa\n0S7i5L6oNpzcH78A1yiltgFW4HGt9UnzqnYdJ/fHY8B/lVKPYpweGa/tt9z4GqXU5xinCiPt10ym\nAIEAWuuZGNdQrgdSgTzgb1W6fR/dr0IIIS6RnDISQggBSCAIIYSwk0AQQggBSCAIIYSwk0AQQggB\nSCAIIYSwk0AQQggBSCAIIYSw+/+DdI4HdqE0BQAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x1a1683d710>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(history['subsample'], history[\"accuracy(train)\"], label='acuracy(train)')\n",
    "plt.plot(history['subsample'], history[\"accuracy(test)\"], label='acuracy(test)')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** max_features **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8.09 s, sys: 546 ms, total: 8.63 s\n",
      "Wall time: 8.65 s\n",
      "max_features = 0.1, train = 0.731219, test = 0.729961\n",
      "CPU times: user 14.7 s, sys: 551 ms, total: 15.3 s\n",
      "Wall time: 15.3 s\n",
      "max_features = 0.3, train = 0.752782, test = 0.751562\n",
      "CPU times: user 21.8 s, sys: 550 ms, total: 22.4 s\n",
      "Wall time: 22.4 s\n",
      "max_features = 0.5, train = 0.756499, test = 0.754417\n",
      "CPU times: user 28.7 s, sys: 550 ms, total: 29.3 s\n",
      "Wall time: 29.3 s\n",
      "max_features = 0.7, train = 0.757353, test = 0.755979\n",
      "CPU times: user 35.3 s, sys: 564 ms, total: 35.9 s\n",
      "Wall time: 35.9 s\n",
      "max_features = 0.9, train = 0.758877, test = 0.756949\n"
     ]
    }
   ],
   "source": [
    "max_features_list = [0.1, 0.3, 0.5, 0.7, 0.9, 1.0]\n",
    "\n",
    "history = []\n",
    "\n",
    "for max_features in max_features_list:\n",
    "    model = GradientBoostingClassifier(n_estimators = 30,\n",
    "                                       max_features = max_features,\n",
    "                                       random_state = 42)\n",
    "    \n",
    "    %time model.fit(X_train, y_train)\n",
    "    \n",
    "    y_train_predict = model.predict(X_train)\n",
    "    y_test_predict = model.predict(X_test)\n",
    "    \n",
    "    train_score = (y_train_predict == y_train).mean()\n",
    "    test_score = (y_test_predict == y_test).mean()\n",
    "    \n",
    "    print(f\"max_features = {max_features}, train = {train_score:.6f}, test = {test_score:.6f}\")\n",
    "    \n",
    "    history.append({\n",
    "        'max_features': max_features,\n",
    "        'accuracy(train)': train_score,\n",
    "        'accuracy(test)': test_score,\n",
    "    })\n",
    "    \n",
    "history = pd.DataFrame(history)\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "plt.plot(history['max_features'], history[\"accuracy(train)\"], label='acuracy(train)')\n",
    "plt.plot(history['max_features'], history[\"accuracy(test)\"], label='acuracy(test)')\n",
    "\n",
    "plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
